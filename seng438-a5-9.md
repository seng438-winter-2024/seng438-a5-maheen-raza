**SENG 438- Software Testing, Reliability, and Quality**

**Lab. Report \#5 â€“ Software Reliability Assessment**

| Group \#:       |   |
|-----------------|---|
| Student Names:  |   |
| Maheen Raza                |   |
|                 |   |
|                 |   |

# Introduction

For our fifth and final assignment, we are provided with different failure reports, that we are expected to convert into different types of graphs in order to understand the overall reliability and failure data of the given system. The main purpose of this assignment is to get a deeper understanding of different reliability assessment tools. Through this lab, we are meant to dive into the following ways to assess the given data:

1. Reliability Growth Testing
2. Assessment with Reliability Demonstration Chart

Through part 1 of the assignment, we are expected to understand the important of reliability growth testing, and why certain plots like time-between-failures and failure-count plots are important in determining the overall system reliability.

In part 2 of the assignment, we are expected to understand how MTTF is relevant in terms of testing, and are also expected to become comfortable with tools that implement RDC.

# 

# Assessment Using Reliability Growth Testing 
### Maheen:
#### Failure Report 2:

In order to decipher failure report 2, in terms of model selection, I only worked with the "Geometric" and "Littlewood and Varral's Bayesian Reliability" models, as the rest of the models would not execute or work on my laptop, so these two models are the ones I decided to select. When looking at these two models, the following conclusions can be made:

Geometric Model:
- The geometric model assume that software failures tend to occur randomly, essentially following a geometric distribution, as indicated by the name.
- The geometric model also tends to be the easiest to understand and implement.

Littlewood and Varral's Bayesian Reliability Model:
- This model assume that software faults tend to occur randomly, and also considers factors like fault removal rates and testing effots.
- Tends to give us a more realistic view on our failure data.

![failure_report_2_tbf_plot](https://github.com/seng438-winter-2024/seng438-a5-maheen-raza/assets/113572260/7af155ce-f667-401c-af93-c967bad26bb0)

Above, I used excel in order to plot the time-between-failures graph, where I graphed failure count against the time-since-last-failure data, providede to us in failure report 2. By observing this graph. the overall system seems to have an upward trajectory, where as time passes, the time between failure starts to grow, meaning we don't have failures back to back as consecutively as we did during the start of the system's operational lifecycle.

![failure_report_2_failure_intensity_plot](https://github.com/seng438-winter-2024/seng438-a5-maheen-raza/assets/113572260/a8cd78f3-3a5c-4bcb-bfaf-5e2d5cf05dc3)

For the above graph, I also used excel in order to plot failure intensity graph by plotting the failure number against the failure time. By observing the failure intensity graph, I can tell that as time failure time increases, so does the failure count. This indicates to me that more time is able to pass before a failure occurs, indicating a potentially more reliable system. If the failures were occuring quicker, more back to back, instead of having an upward linear trajectory, the plot would have a more horizontal line.

![failure_report_2_rdc](https://github.com/seng438-winter-2024/seng438-a5-maheen-raza/assets/113572260/97f0c1ba-1992-4950-baff-68dbe68da053)

#

# Assessment Using Reliability Demonstration Chart 

# 

# Comparison of Results

# Discussion on Similarity and Differences of the Two Techniques

# How the team work/effort was divided and managed

# 

# Difficulties encountered, challenges overcome, and lessons learned

# Comments/feedback on the lab itself
